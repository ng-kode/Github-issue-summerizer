{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/deep_learn_p3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary for tk_body.dpkl: 8000\n",
      "Size of vocabulary for tk_title.dpkl: 4500\n"
     ]
    }
   ],
   "source": [
    "from Helpers import load_tokenizer\n",
    "\n",
    "tk_body = load_tokenizer('tk_body.dpkl')\n",
    "tk_title = load_tokenizer('tk_title.dpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/deep_learn_p3/lib/python3.5/site-packages/keras/engine/topology.py:1253: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Current best 'seq2seq_model_bi1.h5\n",
    "seq2seq_Model = load_model('seq2seq_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract encoder; Re-structure decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = seq2seq_Model.get_layer('Encoder-Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.models import Model\n",
    "\n",
    "def extract_decoder_model(model):\n",
    "    latent_dim = model.get_layer('Title-Word-Embedding').output_shape[-1]\n",
    "    \n",
    "    decoder_inputs = model.get_layer('Decoder-Input').input\n",
    "    dec_emb = model.get_layer('Title-Word-Embedding')(decoder_inputs)\n",
    "    dec_bn = model.get_layer('Decoder-BatchNorm-1')(dec_emb)\n",
    "    \n",
    "    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n",
    "    \n",
    "    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input]) \n",
    "#     gru_out_back, gru_state_out_back = model.get_layer('Decoder-Backward-GRU')([dec_bn, gru_inference_state_input]) \n",
    "    \n",
    "#     gru_out = merge([gru_out, gru_out_back], mode='concat')\n",
    "    \n",
    "    dec_bn2 = model.get_layer('Decoder-BatchNorm-2')(gru_out)\n",
    "    \n",
    "    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n",
    "    \n",
    "    decoder_model = Model([decoder_inputs, gru_inference_state_input],\n",
    "                          [dense_out, gru_state_out])\n",
    "    return decoder_model\n",
    "\n",
    "decoder_model = extract_decoder_model(seq2seq_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue Body:\n",
      " \n",
      "I am trying to implement a LSTM based speech recognizer. So far I could set up bidirectional LSTM (i think it is working as a bidirectional LSTM) by following the example in Merge layer. Now I want to try it with another bidirectional LSTM layer, which make it a deep bidirectional LSTM. But I am unable to figure out how to connect the output of the previously merged two layers into a second set of LSTM layers. I don't know whether it is possible with Keras. Hope someone can help me with this.\n",
      " \n",
      "\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " how to train the model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Helpers import create_title\n",
    "\n",
    "body_text = \"\"\"\n",
    "I am trying to implement a LSTM based speech recognizer. So far I could set up bidirectional LSTM (i think it is working as a bidirectional LSTM) by following the example in Merge layer. Now I want to try it with another bidirectional LSTM layer, which make it a deep bidirectional LSTM. But I am unable to figure out how to connect the output of the previously merged two layers into a second set of LSTM layers. I don't know whether it is possible with Keras. Hope someone can help me with this.\n",
    "\"\"\"\n",
    "\n",
    "create_title(body_text, tk_body, tk_title, encoder_model, decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See some github issues examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('github_issues.csv').sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_text = df.body.tolist()\n",
    "title_text = df.issue_title.tolist()\n",
    "url = df.issue_url.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue Body:\n",
      " could something like this be possible? <script type= text/uniter > echo this is a php statement ; </script> cheers \n",
      "\n",
      "Original Title:\n",
      " html tags for uniter\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " add a way to import a file\n",
      "\n",
      "\n",
      "Issue Body:\n",
      " i'm submitting a ... x bug report => search github for a similar issue or pr before submitting feature request => please check if request is not on the roadmap already https://github.com/primefaces/primeng/wiki/roadmap support request => please do not submit support request here, instead see http://forum.primefaces.org/viewforum.php?f=35 current behavior on checkbox mode, when passing selection with list of items, the partial selection behavior doesn't work no fa-minus icon , the partial selected nodes stays empty. it looks like only on click you trigger the propagate up which sets the partialselected to true. i think you should do the same when setting the selection input. expected behavior set partial selected items with fa-minus icon. angular version: 4.2.6 primeng version: 4.0.3 \n",
      "\n",
      "Original Title:\n",
      " p-tree checkbox mode partialselected issue\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " how to disable the selection of a selected item\n",
      "\n",
      "\n",
      "Issue Body:\n",
      " per morrus: and maybe show the descriptor and max dice pool at the top? eg. a young erudite felan burglar who likes modern art 6d6 this may involve implementing missing pieces of the descriptor. reference: http://www.woinrpg.com/descriptor/ > a n age trait race/heritage career who hook . \n",
      "\n",
      "Original Title:\n",
      " show character descriptor and max dice pool\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " add a way to the\n",
      "\n",
      "\n",
      "Issue Body:\n",
      " host settings > base path i sign permanently visible. \n",
      "\n",
      "Original Title:\n",
      " page header: sign i permanently visible\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " add a config file\n",
      "\n",
      "\n",
      "Issue Body:\n",
      " need a sidebar and a widget that pulls in sub-pages. \n",
      "\n",
      "Original Title:\n",
      " sub-page menu needed on pages\n",
      "\n",
      ">>>>> Generated Title (Prediction): <<<<<\n",
      " add a new tab\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples_idx = np.random.randint(0, len(body_text), 5)\n",
    "for i in samples_idx:\n",
    "    create_title(body_text[i], tk_body, tk_title, encoder_model, decoder_model, title_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
